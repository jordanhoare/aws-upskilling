# üìù Description

This code provisions an AWS API Gateway- and Lambda-based website, and uses DynamoDB to store the hit counter. All infrastructure is "serverless" and pay per usage so there aren't any persistent servers. The project is defined in Python infrastructure as code so that it's easy to spin up and tear down environments without manual steps.

- [ ] Design serverless data lake architecture
- [ ] Build a data processing pipeline and Data Lake using Amazon S3 for storing data
- [ ] Use Amazon Kinesis for real-time streaming data
- [ ] Use AWS Glue to automatically catalog datasets
- [ ] Data Transformation
    - [ ] Run interactive ETL scripts in an Amazon SageMaker Jupyter notebook connected to an AWS Glue development endpoint
    - [ ] Use Glue Studio to run, and monitor ETL jobs in AWS Glue.
    - [ ] Use Glue DataBrew to do data preparation
    - [ ] Use EMR to run a Spark transformation job
- [ ] Load data to Amazon Redshift from Glue
- [ ] Intro into Amazon Redshift Best design practices.
- [ ] Query data using Amazon Athena & visualize it using Amazon QuickSight

![Alt Text](https://media.giphy.com/media/fU1RUGt90DG8xG8EAR/giphy.gif)